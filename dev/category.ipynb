{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2307c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using:\n",
    "# accelerate\n",
    "# torch\n",
    "# open-clip-torch\n",
    "# transformers==4.50.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0187a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type siglip to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoProcessor\n",
    "model = AutoModel.from_pretrained('Marqo/marqo-fashionSigLIP', trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained('Marqo/marqo-fashionSigLIP', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110b8bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: tensor([[3.6853e-05, 1.9796e-05, 2.6209e-06, 9.6477e-06, 5.2416e-04, 4.5374e-06,\n",
      "         3.2650e-06, 2.9837e-05, 3.1002e-05, 6.9482e-07, 2.6150e-05, 2.3374e-04,\n",
      "         2.5366e-04, 3.7345e-04, 8.5314e-05, 1.7657e-03, 1.9929e-01, 4.2040e-01,\n",
      "         9.9107e-04, 2.4575e-04, 1.1863e-04, 7.2447e-04, 3.7191e-01, 2.2294e-05,\n",
      "         9.7894e-05, 1.3273e-04, 1.5372e-05, 1.3254e-04, 2.6753e-05, 2.7658e-05,\n",
      "         1.4968e-05, 8.0561e-06, 1.9771e-04, 9.3901e-04, 4.5827e-06, 2.5403e-06,\n",
      "         5.5583e-04, 1.3674e-05, 1.1177e-04, 7.5405e-07, 7.2951e-06, 1.2556e-06,\n",
      "         5.4257e-05, 1.1594e-06, 1.1010e-05, 2.8758e-06, 2.8536e-04, 9.9389e-05,\n",
      "         3.5251e-05, 2.2810e-06, 8.9891e-08, 1.4575e-06, 3.9779e-06, 4.3518e-05,\n",
      "         2.9554e-06, 4.0098e-06, 4.0959e-06, 2.7068e-06, 4.7752e-07, 5.9204e-05]])\n",
      "Top 3 most probable categories:\n",
      "1. trousers (score: 0.4204)\n",
      "2. chinos (score: 0.3719)\n",
      "3. pants (score: 0.1993)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "image = [Image.open(\"/Users/somogyijanos/Repos/somogyijanos/smartrobe/test-images/00/2025_08_2009_01_320011.JPG\")]\n",
    "# image = [Image.open(\"/Users/somogyijanos/Repos/somogyijanos/smartrobe/test-images/10/IMG_0214.JPG\")]\n",
    "text = [\n",
    "    \"hat\", \"cap\", \"beanie\", \"t-shirt\", \"shirt\", \"blouse\", \"tank top\",\n",
    "    \"polo shirt\", \"sweater\", \"hoodie\", \"cardigan\", \"jacket\", \"coat\",\n",
    "    \"blazer\", \"vest\", \"jeans\", \"pants\", \"trousers\", \"shorts\", \"leggings\", \"sweatpants\",\n",
    "    \"joggers\", \"chinos\", \"skirt\", \"dress\", \"jumpsuit\", \"romper\", \"shoes\",\n",
    "    \"sneakers\", \"boots\", \"sandals\", \"heels\", \"flats\", \"loafers\", \"slippers\", \"athletic shoes\",\n",
    "    \"dress shoes\", \"socks\", \"underwear\", \"bra\", \"swimsuit\", \"bikini\", \"swim trunks\",\n",
    "    \"scarf\", \"gloves\", \"mittens\", \"belt\", \"tie\", \"bow tie\", \"jewelry\", \"necklace\",\n",
    "    \"earrings\", \"bracelet\", \"watch\", \"ring\", \"sunglasses\", \"purse\", \"handbag\", \"backpack\", \"wallet\"\n",
    "]\n",
    "processed = processor(text=text, images=image, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.get_image_features(processed['pixel_values'], normalize=True)\n",
    "    text_features = model.get_text_features(processed['input_ids'], normalize=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs:\", text_probs)\n",
    "\n",
    "# Get the top 3 most probable categories\n",
    "top3_indices = text_probs.argsort(dim=-1, descending=True)[0][:3]\n",
    "top3_categories = [text[idx] for idx in top3_indices]\n",
    "top3_scores = [text_probs[0, idx].item() for idx in top3_indices]\n",
    "\n",
    "print(\"Top 3 most probable categories:\")\n",
    "for i, (category, score) in enumerate(zip(top3_categories, top3_scores), 1):\n",
    "    print(f\"{i}. {category} (score: {score:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
